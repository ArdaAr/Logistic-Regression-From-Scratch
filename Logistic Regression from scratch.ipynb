{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac82d4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.4SP5SUA7CBGXUEOC35YP2ASOICYYEQZZ.gfortran-win_amd64.dll\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m\n",
      "\u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mfit_intercept\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcopy_X\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mpositive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m     \n",
      "Ordinary least squares Linear Regression.\n",
      "\n",
      "LinearRegression fits a linear model with coefficients w = (w1, ..., wp)\n",
      "to minimize the residual sum of squares between the observed targets in\n",
      "the dataset, and the targets predicted by the linear approximation.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "fit_intercept : bool, default=True\n",
      "    Whether to calculate the intercept for this model. If set\n",
      "    to False, no intercept will be used in calculations\n",
      "    (i.e. data is expected to be centered).\n",
      "\n",
      "copy_X : bool, default=True\n",
      "    If True, X will be copied; else, it may be overwritten.\n",
      "\n",
      "n_jobs : int, default=None\n",
      "    The number of jobs to use for the computation. This will only provide\n",
      "    speedup in case of sufficiently large problems, that is if firstly\n",
      "    `n_targets > 1` and secondly `X` is sparse or if `positive` is set\n",
      "    to `True`. ``None`` means 1 unless in a\n",
      "    :obj:`joblib.parallel_backend` context. ``-1`` means using all\n",
      "    processors. See :term:`Glossary <n_jobs>` for more details.\n",
      "\n",
      "positive : bool, default=False\n",
      "    When set to ``True``, forces the coefficients to be positive. This\n",
      "    option is only supported for dense arrays.\n",
      "\n",
      "    .. versionadded:: 0.24\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "coef_ : array of shape (n_features, ) or (n_targets, n_features)\n",
      "    Estimated coefficients for the linear regression problem.\n",
      "    If multiple targets are passed during the fit (y 2D), this\n",
      "    is a 2D array of shape (n_targets, n_features), while if only\n",
      "    one target is passed, this is a 1D array of length n_features.\n",
      "\n",
      "rank_ : int\n",
      "    Rank of matrix `X`. Only available when `X` is dense.\n",
      "\n",
      "singular_ : array of shape (min(X, y),)\n",
      "    Singular values of `X`. Only available when `X` is dense.\n",
      "\n",
      "intercept_ : float or array of shape (n_targets,)\n",
      "    Independent term in the linear model. Set to 0.0 if\n",
      "    `fit_intercept = False`.\n",
      "\n",
      "n_features_in_ : int\n",
      "    Number of features seen during :term:`fit`.\n",
      "\n",
      "    .. versionadded:: 0.24\n",
      "\n",
      "feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "    Names of features seen during :term:`fit`. Defined only when `X`\n",
      "    has feature names that are all strings.\n",
      "\n",
      "    .. versionadded:: 1.0\n",
      "\n",
      "See Also\n",
      "--------\n",
      "Ridge : Ridge regression addresses some of the\n",
      "    problems of Ordinary Least Squares by imposing a penalty on the\n",
      "    size of the coefficients with l2 regularization.\n",
      "Lasso : The Lasso is a linear model that estimates\n",
      "    sparse coefficients with l1 regularization.\n",
      "ElasticNet : Elastic-Net is a linear regression\n",
      "    model trained with both l1 and l2 -norm regularization of the\n",
      "    coefficients.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "From the implementation point of view, this is just plain Ordinary\n",
      "Least Squares (scipy.linalg.lstsq) or Non Negative Least Squares\n",
      "(scipy.optimize.nnls) wrapped as a predictor object.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> import numpy as np\n",
      ">>> from sklearn.linear_model import LinearRegression\n",
      ">>> X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
      ">>> # y = 1 * x_0 + 2 * x_1 + 3\n",
      ">>> y = np.dot(X, np.array([1, 2])) + 3\n",
      ">>> reg = LinearRegression().fit(X, y)\n",
      ">>> reg.score(X, y)\n",
      "1.0\n",
      ">>> reg.coef_\n",
      "array([1., 2.])\n",
      ">>> reg.intercept_\n",
      "3.0...\n",
      ">>> reg.predict(np.array([[3, 5]]))\n",
      "array([16.])\n",
      "\u001b[1;31mFile:\u001b[0m           c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages\\sklearn\\linear_model\\_base.py\n",
      "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[1;31mSubclasses:\u001b[0m     \n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "LinearRegression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps for Logistic Regression\n",
    "\n",
    "LR is similar with Linear Regression but instead of predict a continous value, LogReg predict the probability between 0 and 1 value\n",
    "\n",
    "Training :\n",
    "- Initialize weights as zero\n",
    "- Initialize bias as zero\n",
    "\n",
    "Given a data point:\n",
    "- Predict result by using Logreg equation \n",
    "- calculate error\n",
    "- use gradient descent to figure out new weight and bias values\n",
    "- repeat n times\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3b964c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46cdfb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "x = np.array([3,2,5,6,1])\n",
    "weights = np.zeros(x.shape)\n",
    "\n",
    "print(np.dot(x,weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "class LogisticReg():\n",
    "\n",
    "    def __init__(self, lr=0.001, n_iters=1000):\n",
    "        self.lr = lr\n",
    "        self.n_iters= n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # mengambil banyaknya baris data dan attribute dari shape\n",
    "        # setiap weight akan dikalikan dengan atribut sehingga ketika weight di inisiasi menjadi 0, kita harus memiliki matrix 0 yang...\n",
    "        # ... berjumlah n_features data karena masing-masing atribut dikalikan dengan weight\n",
    "        print('shape awal: ', X.shape)\n",
    "        print('shape transpose: ', X.T.shape)\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        print('shape weight 0: ', self.weights.shape)\n",
    "        self.bias = 0 # bias langsung diinisiasi 0 karena dalam perhitungan tidak dikalikan dengan atribut namun hanya sebagai konstanta penjumlah\n",
    "\n",
    "        for _ in range(self.n_iters):\n",
    "            linear_pred = np.dot(X, self.weights) + self.bias\n",
    "            prediction = sigmoid(linear_pred)\n",
    "\n",
    "            dw = (1/n_samples) * np.dot(X.T, (prediction - y))\n",
    "            db = (1/n_samples) * np.sum(prediction - y)\n",
    "\n",
    "            self.weights = self.weights - self.lr*dw\n",
    "            self.bias = self.bias - self.lr*db\n",
    "\n",
    "    def predict(self,X):\n",
    "        linear_pred = np.dot(X,self.weights) + self.bias\n",
    "        y_pred = sigmoid(linear_pred) # y_pred adalah list probability hasil prediksi\n",
    "        # print('y_pred = ', y_pred)\n",
    "\n",
    "        label = [ 0 if y <= 0.5 else 1 for y in y_pred ]\n",
    "        return label\n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "bc = datasets.load_breast_cancer()\n",
    "X, y = bc.data, bc.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape awal:  (455, 30)\n",
      "shape transpose:  (30, 455)\n",
      "shape weight 0:  (30,)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticReg(lr=0.0001)\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(3, 3)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([\n",
    "    [1,2,3], \n",
    "    [4,5,6]])\n",
    "y = np.array([\n",
    "    [6,7,8],\n",
    "    [6,5,4],\n",
    "    [3,2,1]\n",
    "])\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27, 23, 19],\n",
       "       [72, 65, 58]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "def accuracy(y_pred, y_test):\n",
    "    return (np.sum(y_pred==y_test))/len(y_test)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "acc = accuracy(y_pred,y_test)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pahami np.dot dan urutan parameternya\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
